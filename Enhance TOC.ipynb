{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Migration Legislation Annotations - TOC Generator\n",
    "\n",
    "## Planning & Approach\n",
    "\n",
    "### Key Information:\n",
    "- **TOC Location**: Pages 12-13 of the PDF file\n",
    "- **TOC Format**: `[Title]....[Page number|Roman number]`\n",
    "- **Page Offset**: Document page 1 starts at PDF page 43; Roman number start at PDF page 1\n",
    "- **Approach**: Self-contained notebook with verification at each step\n",
    "\n",
    "### TOC Format Nuances & Exceptions:\n",
    "- **Multiline Entries**: Long titles may span across multiple lines with the page number on the final line\n",
    "  - Example: \n",
    "    ```\n",
    "    Part 7AA ‚Äì Fast track review process in relation to certain protection visa decisions\n",
    "    (ss 473BA‚Äì473JF) ........................................................................................................................... 947\n",
    "    ```\n",
    "  - Correct detection: Title = \"Part 7AA ‚Äì Fast track review process in relation to certain protection visa decisions (ss 473BA‚Äì473JF)\", Page = 947\n",
    "- **Mixed Numbering**: Roman numerals (v, vii, xiii, xix) for preliminary pages, Arabic (1, 3, 27) for main content\n",
    "- **Dot Leaders**: Variable length dots between title and page number (minimum 3 dots)\n",
    "- **Section References**: Titles may include section references in parentheses (e.g., \"ss 1‚Äì12\", \"ss 473BA‚Äì473JF\")\n",
    "- **Special Characters**: Titles may contain em-dashes (‚Äî), hyphens (-), and other punctuation\n",
    "\n",
    "### Implementation Plan:\n",
    "\n",
    "#### Phase 1: Analysis & Verification\n",
    "1. **PDF Structure Analysis** - Verify PDF properties and page count\n",
    "2. **TOC Pages Inspection** - Extract and examine pages 11-12 content\n",
    "3. **Page Offset Verification** - Confirm page 1 starts at PDF page 43\n",
    "\n",
    "#### Phase 2: TOC Extraction\n",
    "4. **Raw TOC Extraction** - Extract text from TOC pages\n",
    "5. **TOC Pattern Parsing** - Parse `[Title]....[Page number]` patterns with multiline support\n",
    "6. **Multiline Entry Handling** - Detect and merge entries that span multiple lines\n",
    "7. **Page Number Mapping** - Apply offset based on numbering type (roman vs arabic)\n",
    "8. **Data Validation** - Verify extracted entries against sample pages\n",
    "\n",
    "#### Phase 3: TOC Generation\n",
    "9. **Hierarchical Structure** - Organize entries by level (Parts, Divisions, Sections)\n",
    "10. **TOC Formatting** - Generate properly formatted TOC text\n",
    "11. **PDF Integration** - Create new PDF with TOC page and bookmarks\n",
    "\n",
    "#### Phase 4: Quality Assurance\n",
    "12. **Verification Testing** - Test TOC links and navigation\n",
    "13. **Output Validation** - Ensure enhanced PDF maintains original content\n",
    "14. **Final Audit** - Complete verification of all TOC entries\n",
    "\n",
    "### Success Criteria:\n",
    "- ‚úÖ All TOC entries correctly extracted from pages 11-12\n",
    "- ‚úÖ Page numbers properly mapped with offset calculation\n",
    "- ‚úÖ Enhanced PDF with functional TOC and bookmarks\n",
    "- ‚úÖ Every step auditable and reproducible\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99147353",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 1: Setup & PDF Structure Analysis\n",
    "\n",
    "First, let's import required libraries and analyze the PDF structure to verify our assumptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50b3a5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Migration Legislation TOC Generator\n",
      "==================================================\n",
      "PyMuPDF version: 1.26.3\n",
      "PDF file: Migration Legislation Annotations.pdf\n",
      "TOC pages: [11, 12]\n",
      "Page offset: 43 (document page 1 = PDF page 43)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#2Import required libraries\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import os\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Configuration\n",
    "PDF_PATH = \"Migration Legislation Annotations.pdf\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "TOC_PAGES = [11, 12]  # PDF pages containing TOC\n",
    "PAGE_OFFSET = 44 - 2  # Document page 1 starts at PDF page 44 (0-indexed: 42)\n",
    "\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"üìö Migration Legislation TOC Generator\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"PyMuPDF version: {fitz.version[0]}\")\n",
    "print(f\"PDF file: {PDF_PATH}\")\n",
    "print(f\"TOC pages: {TOC_PAGES}\")\n",
    "print(f\"Page offset: {PAGE_OFFSET + 1} (document page 1 = PDF page {PAGE_OFFSET + 1})\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9173c379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Step 1: PDF Structure Analysis\n",
      "------------------------------\n",
      "üìÑ PDF Information:\n",
      "   filename: Migration Legislation Annotations.pdf\n",
      "   page_count: 2120\n",
      "   title: Migration Legislation with Annotations\n",
      "   author: Natasha Bosnjak; Ben Petrie; \n",
      "   creator: XyEnterprise XPP 8.4C.1\n",
      "   file_size_mb: 7.36\n",
      "\n",
      "üîç Verifying TOC pages [11, 12]:\n",
      "   Page 11: ‚úÖ Exists (5493 characters)\n",
      "   Page 12: ‚úÖ Exists (3496 characters)\n",
      "\n",
      "üîç Verifying page offset (document page 1 = PDF page 43):\n",
      "   PDF page 43 content sample:\n",
      "   'Migration Act 1958\n",
      "Annotated Migration Act with Related\n",
      "Commentary\n",
      "...'\n",
      "   ‚ö†Ô∏è  May not be document page 1 - please verify\n",
      "\n",
      "‚úÖ Step 1 Complete: PDF structure verified\n"
     ]
    }
   ],
   "source": [
    "# Analyze PDF structur\n",
    "print(\"üîç Step 1: PDF Structure Analysis\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Open PDF and get basic information\n",
    "doc = fitz.open(PDF_PATH)\n",
    "\n",
    "pdf_info = {\n",
    "    'filename': PDF_PATH,\n",
    "    'page_count': len(doc),\n",
    "    'title': doc.metadata.get('title', 'Unknown'),\n",
    "    'author': doc.metadata.get('author', 'Unknown'),\n",
    "    'creator': doc.metadata.get('creator', 'Unknown'),\n",
    "    'file_size_mb': round(os.path.getsize(PDF_PATH) / (1024*1024), 2)\n",
    "}\n",
    "\n",
    "print(\"üìÑ PDF Information:\")\n",
    "for key, value in pdf_info.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Verify TOC pages exist\n",
    "print(f\"\\nüîç Verifying TOC pages {TOC_PAGES}:\")\n",
    "for page_num in TOC_PAGES:\n",
    "    if page_num <= len(doc):\n",
    "        page = doc[page_num - 1]  # Convert to 0-indexed\n",
    "        text_length = len(page.get_text())\n",
    "        print(f\"   Page {page_num}: ‚úÖ Exists ({text_length} characters)\")\n",
    "    else:\n",
    "        print(f\"   Page {page_num}: ‚ùå Does not exist!\")\n",
    "\n",
    "# Verify page offset assumption\n",
    "print(f\"\\nüîç Verifying page offset (document page 1 = PDF page {PAGE_OFFSET + 1}):\")\n",
    "if PAGE_OFFSET + 1 <= len(doc):\n",
    "    offset_page = doc[PAGE_OFFSET]  # PAGE_OFFSET is already 0-indexed\n",
    "    text_sample = offset_page.get_text()\n",
    "    print(f\"   PDF page {PAGE_OFFSET + 1} content sample:\")\n",
    "    print(f\"   '{text_sample}...'\")\n",
    "    \n",
    "    # Look for indicators that this is page 1 of the document\n",
    "    if any(indicator in text_sample.lower() for indicator in ['Act']):\n",
    "        print(\"   ‚úÖ Likely contains document page 1 content\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  May not be document page 1 - please verify\")\n",
    "else:\n",
    "    print(f\"   ‚ùå PDF page {PAGE_OFFSET + 1} does not exist!\")\n",
    "\n",
    "doc.close()\n",
    "print(\"\\n‚úÖ Step 1 Complete: PDF structure verified\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: TOC Pages Inspection\n",
    "\n",
    "Extract and examine the content from TOC pages to understand the format and structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc5f7b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Step 2: TOC Pages Inspection\n",
      "------------------------------\n",
      "\n",
      "üìÑ Extracting content from page 11:\n",
      "   Total lines: 45\n",
      "   Non-empty lines: 44\n",
      "   Characters: 5493\n",
      "   Sample lines:\n",
      "     1. CONTENTS\n",
      "     2. Foreword ...................................................................................................................................................... v\n",
      "     3. Preface ........................................................................................................................................................ vii\n",
      "     4. About this publication ............................................................................................................................... xiii\n",
      "     5. About the authors ...................................................................................................................................... xix\n",
      "\n",
      "üìÑ Extracting content from page 12:\n",
      "   Total lines: 31\n",
      "   Non-empty lines: 30\n",
      "   Characters: 3496\n",
      "   Sample lines:\n",
      "     1. Schedule 4 ‚Äì Public interest criteria and related provisions ................................................................ 1699\n",
      "     2. Schedule 5 ‚Äî Special return criteria .................................................................................................... 1713\n",
      "     3. Schedule 5A ‚Äì Evidentiary requirements for student visas .................................................................. 1717\n",
      "     4. Schedule 5B ‚Äì Evidentiary requirements for student visa ‚Äì secondary applicants ............................. 1755\n",
      "     5. Schedules 6‚Äì6C ‚Äì General points tests [Repealed] .............................................................................. 1761\n",
      "\n",
      "üíæ Raw TOC text saved to: output/raw_toc_text.txt\n",
      "\n",
      "üîç Pattern Analysis:\n",
      "   üìù Adding manual 'Contents' entry (page xi)\n",
      "   Lines matching TOC pattern: 65\n",
      "   Total lines in TOC pages: 74\n",
      "   Multiline/Manual entries detected: 1\n",
      "\n",
      "üìù Sample TOC pattern matches:\n",
      "   1. Title: 'Contents' -> Page: 11 (roman) (multiline)\n",
      "      Full line: 'Contents (manual entry)'\n",
      "   2. Title: 'Foreword' -> Page: 5 (roman)\n",
      "      Full line: 'Foreword ..............................................................................................'\n",
      "   3. Title: 'Preface' -> Page: 7 (roman)\n",
      "      Full line: 'Preface ...............................................................................................'\n",
      "   4. Title: 'About this publication' -> Page: 13 (roman)\n",
      "      Full line: 'About this publication ................................................................................'\n",
      "   5. Title: 'About the authors' -> Page: 19 (roman)\n",
      "      Full line: 'About the authors .....................................................................................'\n",
      "   6. Title: 'Table of Cases' -> Page: 21 (roman)\n",
      "      Full line: 'Table of Cases ........................................................................................'\n",
      "   7. Title: 'MIGRATION ACT 1958' -> Page: 1 (arabic)\n",
      "      Full line: 'MIGRATION ACT 1958 ....................................................................................'\n",
      "   8. Title: 'Table of Provisions' -> Page: 3 (arabic)\n",
      "      Full line: 'Table of Provisions ...................................................................................'\n",
      "   9. Title: 'Table of Amending Legislation' -> Page: 27 (arabic)\n",
      "      Full line: 'Table of Amending Legislation .........................................................................'\n",
      "   10. Title: 'Table of Annotations' -> Page: 51 (arabic)\n",
      "      Full line: 'Table of Annotations ..................................................................................'\n",
      "\n",
      "‚úÖ Step 2 Complete: Found 65 potential TOC entries\n"
     ]
    }
   ],
   "source": [
    "# Extract TOC pages content\n",
    "print(\"üîç Step 2: TOC Pages Inspection\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "doc = fitz.open(PDF_PATH)\n",
    "\n",
    "# Extract text from each TOC page\n",
    "toc_raw_text = \"\"\n",
    "for page_num in TOC_PAGES:\n",
    "    print(f\"\\nüìÑ Extracting content from page {page_num}:\")\n",
    "    page = doc[page_num - 1]  # Convert to 0-indexed\n",
    "    page_text = page.get_text()\n",
    "    toc_raw_text += page_text + \"\\n\"\n",
    "    \n",
    "    lines = page_text.split('\\n')\n",
    "    non_empty_lines = [line.strip() for line in lines if line.strip()]\n",
    "    \n",
    "    print(f\"   Total lines: {len(lines)}\")\n",
    "    print(f\"   Non-empty lines: {len(non_empty_lines)}\")\n",
    "    print(f\"   Characters: {len(page_text)}\")\n",
    "    \n",
    "    # Show first few lines as sample\n",
    "    print(f\"   Sample lines:\")\n",
    "    for i, line in enumerate(non_empty_lines[:5]):\n",
    "        print(f\"     {i+1}. {line}\")\n",
    "\n",
    "# Save raw TOC text for inspection\n",
    "raw_toc_file = f\"{OUTPUT_DIR}/raw_toc_text.txt\"\n",
    "with open(raw_toc_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(toc_raw_text)\n",
    "\n",
    "print(f\"\\nüíæ Raw TOC text saved to: {raw_toc_file}\")\n",
    "\n",
    "# Analyze patterns in the TOC\n",
    "print(f\"\\nüîç Pattern Analysis:\")\n",
    "lines = toc_raw_text.split('\\n')\n",
    "lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "# Look for lines with dots and page numbers (TOC pattern) - including roman numerals\n",
    "toc_pattern = re.compile(r'^(.+?)\\.{3,}\\s*([ivxlcdm]+|\\d+)$', re.IGNORECASE)\n",
    "potential_toc_lines = []\n",
    "\n",
    "def roman_to_int(roman):\n",
    "    \"\"\"Convert roman numeral to integer\"\"\"\n",
    "    if not roman:\n",
    "        return 0\n",
    "    \n",
    "    roman = roman.upper()\n",
    "    values = {'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000}\n",
    "    total = 0\n",
    "    prev_value = 0\n",
    "    \n",
    "    for char in reversed(roman):\n",
    "        value = values.get(char, 0)\n",
    "        if value < prev_value:\n",
    "            total -= value\n",
    "        else:\n",
    "            total += value\n",
    "        prev_value = value\n",
    "    \n",
    "    return total\n",
    "\n",
    "def is_roman_numeral(s):\n",
    "    \"\"\"Check if string is a roman numeral\"\"\"\n",
    "    return bool(re.match(r'^[ivxlcdm]+$', s, re.IGNORECASE))\n",
    "\n",
    "def process_multiline_toc_entries(lines):\n",
    "    \"\"\"Process TOC entries that may span multiple lines\"\"\"\n",
    "    processed_entries = []\n",
    "    i = 0\n",
    "    \n",
    "    def is_valid_toc_start(line):\n",
    "        \"\"\"Check if a line could be the start of a valid TOC entry\"\"\"\n",
    "        line = line.strip()\n",
    "        # Skip copyright notices, page headers, and other non-TOC content\n",
    "        skip_patterns = [\n",
    "            r'^¬©.*THOMSON REUTERS',  # Copyright lines\n",
    "            r'^\\d+$',                # Standalone page numbers\n",
    "            r'^[ivxlcdm]+$',         # Standalone roman numerals\n",
    "            r'^Migration.*Annotations$',  # Document headers\n",
    "            r'^CONTENTS$',           # Standalone \"CONTENTS\" (we handle this manually)\n",
    "            r'^\\s*$'                 # Empty lines\n",
    "        ]\n",
    "        \n",
    "        for pattern in skip_patterns:\n",
    "            if re.match(pattern, line, re.IGNORECASE):\n",
    "                return False\n",
    "        \n",
    "        # Must contain actual content (letters/words)\n",
    "        if not re.search(r'[a-zA-Z]', line):\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        match = toc_pattern.match(line)\n",
    "        \n",
    "        if match:\n",
    "            # Found a complete TOC entry on single line\n",
    "            title = match.group(1).strip()\n",
    "            page_str = match.group(2).strip()\n",
    "            \n",
    "            # Convert page number (roman or arabic)\n",
    "            if is_roman_numeral(page_str):\n",
    "                page_num = roman_to_int(page_str)\n",
    "                page_type = 'roman'\n",
    "            else:\n",
    "                page_num = int(page_str)\n",
    "                page_type = 'arabic'\n",
    "            \n",
    "            processed_entries.append((title, page_num, line, page_type))\n",
    "            i += 1\n",
    "        else:\n",
    "            # Check if this might be the start of a multiline entry\n",
    "            potential_title = line.strip()\n",
    "            \n",
    "            # Skip lines that can't be valid TOC starts\n",
    "            if not is_valid_toc_start(potential_title):\n",
    "                i += 1\n",
    "                continue\n",
    "                \n",
    "            found_multiline = False\n",
    "            \n",
    "            # Look ahead up to 3 lines for the page number\n",
    "            for j in range(i + 1, min(i + 4, len(lines))):\n",
    "                next_line = lines[j].strip()\n",
    "                \n",
    "                # Check if this line ends with dots and page number\n",
    "                multiline_match = toc_pattern.match(next_line)\n",
    "                if multiline_match:\n",
    "                    # Found the continuation with page number\n",
    "                    continuation_title = multiline_match.group(1).strip()\n",
    "                    page_str = multiline_match.group(2).strip()\n",
    "                    \n",
    "                    # Use only the continuation title if it exists, otherwise use potential_title\n",
    "                    if continuation_title:\n",
    "                        # If continuation has substantial content, use it as the main title\n",
    "                        if len(continuation_title) > len(potential_title) * 0.5:\n",
    "                            combined_title = continuation_title\n",
    "                        else:\n",
    "                            combined_title = f\"{potential_title} {continuation_title}\"\n",
    "                    else:\n",
    "                        combined_title = potential_title\n",
    "                    \n",
    "                    # Convert page number\n",
    "                    if is_roman_numeral(page_str):\n",
    "                        page_num = roman_to_int(page_str)\n",
    "                        page_type = 'roman'\n",
    "                    else:\n",
    "                        page_num = int(page_str)\n",
    "                        page_type = 'arabic'\n",
    "                    \n",
    "                    # Create combined line for reference\n",
    "                    combined_line = f\"{potential_title} {next_line}\"\n",
    "                    \n",
    "                    processed_entries.append((combined_title, page_num, combined_line, page_type))\n",
    "                    found_multiline = True\n",
    "                    i = j + 1  # Skip to after the found continuation\n",
    "                    break\n",
    "                elif next_line and is_valid_toc_start(next_line) and not next_line.startswith(('Part', 'Schedule', 'Division', 'Section')):\n",
    "                    # This might be a continuation line, add it to potential title\n",
    "                    potential_title += f\" {next_line}\"\n",
    "                else:\n",
    "                    # Hit another potential TOC entry or invalid line, stop looking\n",
    "                    break\n",
    "            \n",
    "            if not found_multiline:\n",
    "                # No multiline match found, skip this line\n",
    "                i += 1\n",
    "    \n",
    "    return processed_entries\n",
    "\n",
    "# Process entries with multiline support\n",
    "potential_toc_lines = process_multiline_toc_entries(lines)\n",
    "\n",
    "# Add manual \"Contents\" entry if not found (roman page xi = 11)\n",
    "contents_found = any(entry[0].lower() == 'contents' for entry in potential_toc_lines)\n",
    "if not contents_found:\n",
    "    print(\"   üìù Adding manual 'Contents' entry (page xi)\")\n",
    "    potential_toc_lines.insert(0, (\"Contents\", 11, \"Contents (manual entry)\", \"roman\"))\n",
    "\n",
    "print(f\"   Lines matching TOC pattern: {len(potential_toc_lines)}\")\n",
    "print(f\"   Total lines in TOC pages: {len(lines)}\")\n",
    "\n",
    "# Analyze multiline entries\n",
    "multiline_entries = [entry for entry in potential_toc_lines if '\\n' in entry[2] or 'manual entry' in entry[2]]\n",
    "print(f\"   Multiline/Manual entries detected: {len(multiline_entries)}\")\n",
    "\n",
    "# Show sample matches\n",
    "print(f\"\\nüìù Sample TOC pattern matches:\")\n",
    "for i, (title, page_num, full_line, page_type) in enumerate(potential_toc_lines[:10]):\n",
    "    multiline_indicator = \" (multiline)\" if '\\n' in full_line or 'manual' in full_line else \"\"\n",
    "    print(f\"   {i+1}. Title: '{title}' -> Page: {page_num} ({page_type}){multiline_indicator}\")\n",
    "    print(f\"      Full line: '{full_line[:100]}{'...' if len(full_line) > 100 else ''}'\")\n",
    "\n",
    "doc.close()\n",
    "print(f\"\\n‚úÖ Step 2 Complete: Found {len(potential_toc_lines)} potential TOC entries\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: TOC Entry Processing & Validation\n",
    "\n",
    "Parse the TOC entries, apply page offset mapping, and validate against actual content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46dc0e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Step 3: TOC Entry Processing & Validation\n",
      "----------------------------------------\n",
      "üìä Processing Results:\n",
      "   Total entries processed: 65\n",
      "   Hierarchy levels: {0: 65}\n",
      "\n",
      "üìù Sample processed entries:\n",
      "   1. Contents\n",
      "      Doc page: 11 (roman) -> PDF page: 11\n",
      "      Level: 0\n",
      "   2. Foreword\n",
      "      Doc page: 5 (roman) -> PDF page: 5\n",
      "      Level: 0\n",
      "   3. Preface\n",
      "      Doc page: 7 (roman) -> PDF page: 7\n",
      "      Level: 0\n",
      "   4. About this publication\n",
      "      Doc page: 13 (roman) -> PDF page: 13\n",
      "      Level: 0\n",
      "   5. About the authors\n",
      "      Doc page: 19 (roman) -> PDF page: 19\n",
      "      Level: 0\n",
      "   6. Table of Cases\n",
      "      Doc page: 21 (roman) -> PDF page: 21\n",
      "      Level: 0\n",
      "   7. MIGRATION ACT 1958\n",
      "      Doc page: 1 (arabic) -> PDF page: 43\n",
      "      Level: 0\n",
      "   8. Table of Provisions\n",
      "      Doc page: 3 (arabic) -> PDF page: 45\n",
      "      Level: 0\n",
      "   9. Table of Amending Legislation\n",
      "      Doc page: 27 (arabic) -> PDF page: 69\n",
      "      Level: 0\n",
      "   10. Table of Annotations\n",
      "      Doc page: 51 (arabic) -> PDF page: 93\n",
      "      Level: 0\n",
      "\n",
      "üíæ TOC structure saved to: output/toc_structure.json\n",
      "   üìä Contains 65 entries with metadata\n",
      "   üìÑ JSON file size: 11.6 KB\n",
      "\n",
      "‚úÖ Step 3 Complete: 65 TOC entries processed and saved to JSON\n"
     ]
    }
   ],
   "source": [
    "# Define TOC Entry data structure\n",
    "@dataclass\n",
    "class TOCEntry:\n",
    "    title: str\n",
    "    document_page: int  # Page number as shown in document\n",
    "    pdf_page: int       # Actual PDF page (with offset applied)\n",
    "    level: int          # Hierarchy level (1=Part, 2=Division, 3=Section)\n",
    "    page_type: str      # 'roman' or 'arabic'\n",
    "\n",
    "print(\"üîç Step 3: TOC Entry Processing & Validation\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Process TOC entries\n",
    "toc_entries = []\n",
    "for title, doc_page, full_line, page_type in potential_toc_lines:\n",
    "    # Apply page offset based on page type\n",
    "    if page_type == 'roman':\n",
    "        # Roman numerals start at PDF page 1 (no offset needed)\n",
    "        pdf_page = doc_page\n",
    "    else:\n",
    "        # Arabic numerals: document page 1 starts at PDF page 43\n",
    "        pdf_page = doc_page + PAGE_OFFSET\n",
    "    \n",
    "    # Create TOC entry\n",
    "    entry = TOCEntry(\n",
    "        title=title,\n",
    "        document_page=doc_page,\n",
    "        pdf_page=pdf_page,\n",
    "        level=0,\n",
    "        page_type=page_type,\n",
    "    )\n",
    "    toc_entries.append(entry)\n",
    "\n",
    "print(f\"üìä Processing Results:\")\n",
    "print(f\"   Total entries processed: {len(toc_entries)}\")\n",
    "\n",
    "# Analyze entry types\n",
    "type_counts = {}\n",
    "level_counts = {}\n",
    "for entry in toc_entries:\n",
    "    level_counts[entry.level] = level_counts.get(entry.level, 0) + 1\n",
    "\n",
    "print(f\"   Hierarchy levels: {dict(sorted(level_counts.items()))}\")\n",
    "\n",
    "# Show sample processed entries\n",
    "print(f\"\\nüìù Sample processed entries:\")\n",
    "for i, entry in enumerate(toc_entries[:10]):\n",
    "    print(f\"   {i+1}. {entry.title}\")\n",
    "    print(f\"      Doc page: {entry.document_page} ({entry.page_type}) -> PDF page: {entry.pdf_page}\")\n",
    "    print(f\"      Level: {entry.level}\")\n",
    "\n",
    "# Save TOC entries to JSON file for use in Step 5\n",
    "import json\n",
    "\n",
    "toc_data = {\n",
    "    \"metadata\": {\n",
    "        \"total_entries\": len(toc_entries),\n",
    "        \"extraction_date\": \"2024-01-01\",  # You can use datetime.now().isoformat() for actual date\n",
    "        \"source_pages\": TOC_PAGES,\n",
    "        \"page_offset\": PAGE_OFFSET\n",
    "    },\n",
    "    \"entries\": []\n",
    "}\n",
    "\n",
    "# Convert TOC entries to dictionary format for JSON serialization\n",
    "for entry in toc_entries:\n",
    "    entry_dict = {\n",
    "        \"title\": entry.title,\n",
    "        \"document_page\": entry.document_page,\n",
    "        \"pdf_page\": entry.pdf_page,\n",
    "        \"level\": entry.level,\n",
    "        \"page_type\": entry.page_type\n",
    "    }\n",
    "    toc_data[\"entries\"].append(entry_dict)\n",
    "\n",
    "# Save to JSON file\n",
    "toc_json_file = f\"{OUTPUT_DIR}/toc_structure.json\"\n",
    "with open(toc_json_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(toc_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nüíæ TOC structure saved to: {toc_json_file}\")\n",
    "print(f\"   üìä Contains {len(toc_entries)} entries with metadata\")\n",
    "print(f\"   üìÑ JSON file size: {round(os.path.getsize(toc_json_file) / 1024, 1)} KB\")\n",
    "\n",
    "print(f\"\\n‚úÖ Step 3 Complete: {len(toc_entries)} TOC entries processed and saved to JSON\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 4: Content Validation\n",
    "\n",
    "Verify that our TOC entries point to the correct pages by sampling actual content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "979028a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Step 4: Content Validation\n",
      "------------------------------\n",
      "üìä Validating sample TOC entries...\n",
      "   1. ‚úÖ Contents\n",
      "      Page 11 -> PDF page 11\n",
      "      Match score: 1.00\n",
      "      Content preview: 'CONTENTS\n",
      "Foreword .....................................................................................'\n",
      "   2. ‚úÖ Foreword\n",
      "      Page 5 -> PDF page 5\n",
      "      Match score: 1.00\n",
      "      Content preview: 'FOREWORD\n",
      "In Australia migration law has a long and complex history reÔ¨Çected in a vast array of visa\n",
      "...'\n",
      "   3. ‚úÖ Preface\n",
      "      Page 7 -> PDF page 7\n",
      "      Match score: 1.00\n",
      "      Content preview: 'PREFACE\n",
      "The question of how to treat foreigners has long occupied a central place in Australia‚Äôs nat...'\n",
      "   4. ‚úÖ About this publication\n",
      "      Page 13 -> PDF page 13\n",
      "      Match score: 1.00\n",
      "      Content preview: 'ABOUT THIS PUBLICATION\n",
      "SCOPE OF THIS WORK\n",
      "Migration Law ‚Äì Annotated Migration Act with Related Legis...'\n",
      "   5. ‚úÖ About the authors\n",
      "      Page 19 -> PDF page 19\n",
      "      Match score: 1.00\n",
      "      Content preview: 'ABOUT THE AUTHORS\n",
      "Ben Petrie, LLB (Hons), BA, BSc\n",
      "Ben Petrie has a broad commercial and public law p...'\n",
      "   6. ‚úÖ Table of Cases\n",
      "      Page 21 -> PDF page 21\n",
      "      Match score: 1.00\n",
      "      Content preview: 'TABLE OF CASES\n",
      "A\n",
      "A v Minister for Immigration and Ethnic Affairs (1997) 190 CLR 225; 142 ALR 331; 71...'\n",
      "   7. ‚úÖ MIGRATION ACT 1958\n",
      "      Page 1 -> PDF page 43\n",
      "      Match score: 1.00\n",
      "      Content preview: 'Migration Act 1958\n",
      "Annotated Migration Act with Related\n",
      "Commentary\n",
      "...'\n",
      "   8. ‚úÖ Table of Provisions\n",
      "      Page 3 -> PDF page 45\n",
      "      Match score: 1.00\n",
      "      Content preview: 'TABLE OF PROVISIONS\n",
      "Part 1 - Preliminary\n",
      "1\n",
      "Short title.................................................'\n",
      "   9. ‚úÖ Table of Amending Legislation\n",
      "      Page 27 -> PDF page 69\n",
      "      Match score: 1.00\n",
      "      Content preview: 'TABLE OF AMENDING LEGISLATION\n",
      "Principal legislation\n",
      "Number\n",
      "Date of\n",
      "gazettal/assent/\n",
      "registration\n",
      "Dat...'\n",
      "   10. ‚úÖ Table of Annotations\n",
      "      Page 51 -> PDF page 93\n",
      "      Match score: 1.00\n",
      "      Content preview: 'TABLE OF ANNOTATIONS\n",
      "Part 1 ...........................................................................'\n",
      "\n",
      "üìä Validation Summary (sample of 10):\n",
      "   Pages exist: 10/10 (100.0%)\n",
      "   Content matches: 10/10 (100.0%)\n",
      "\n",
      "üìä Page Range Analysis:\n",
      "   TOC page range: 5 to 2051\n",
      "   PDF total pages: 2120\n",
      "   Range validity: ‚úÖ Valid\n",
      "\n",
      "‚úÖ Step 4 Complete: Validation results available for analysis\n"
     ]
    }
   ],
   "source": [
    "# Validate TOC entries against actual content\n",
    "print(\"üîç Step 4: Content Validation\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "doc = fitz.open(PDF_PATH)\n",
    "\n",
    "def validate_toc_entry(entry: TOCEntry, doc: fitz.Document) -> Dict[str, any]:\n",
    "    \"\"\"Validate a single TOC entry against actual page content\"\"\"\n",
    "    result = {\n",
    "        'entry': entry,\n",
    "        'valid': False,\n",
    "        'page_exists': False,\n",
    "        'content_match': False,\n",
    "        'page_content': '',\n",
    "        'match_score': 0.0\n",
    "    }\n",
    "    \n",
    "    # Check if PDF page exists\n",
    "    if 0 <= entry.pdf_page - 1 < len(doc):  # Convert to 0-indexed\n",
    "        result['page_exists'] = True\n",
    "        page = doc[entry.pdf_page - 1]\n",
    "        page_content = page.get_text()\n",
    "        result['page_content'] = page_content[:300]  # First 300 chars\n",
    "        \n",
    "        # Simple content matching\n",
    "        title_words = entry.title.lower().split()\n",
    "        content_lower = page_content.lower()\n",
    "        \n",
    "        # Count how many title words appear in the page content\n",
    "        matches = sum(1 for word in title_words if word in content_lower)\n",
    "        if len(title_words) > 0:\n",
    "            result['match_score'] = matches / len(title_words)\n",
    "            result['content_match'] = result['match_score'] > 0.3  # 30% threshold\n",
    "        \n",
    "        result['valid'] = result['page_exists'] and result['content_match']\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Validate sample entries (first 10 for quick verification)\n",
    "print(\"üìä Validating sample TOC entries...\")\n",
    "validation_results = []\n",
    "sample_entries = toc_entries[:10]\n",
    "\n",
    "for i, entry in enumerate(sample_entries):\n",
    "    result = validate_toc_entry(entry, doc)\n",
    "    validation_results.append(result)\n",
    "    \n",
    "    status = \"‚úÖ\" if result['valid'] else \"‚ùå\"\n",
    "    print(f\"   {i+1}. {status} {entry.title}\")\n",
    "    print(f\"      Page {entry.document_page} -> PDF page {entry.pdf_page}\")\n",
    "    print(f\"      Match score: {result['match_score']:.2f}\")\n",
    "    if result['page_exists']:\n",
    "        print(f\"      Content preview: '{result['page_content'][:100]}...'\")\n",
    "    else:\n",
    "        print(f\"      ‚ùå Page does not exist!\")\n",
    "\n",
    "# Summary statistics\n",
    "valid_count = sum(1 for r in validation_results if r['valid'])\n",
    "page_exists_count = sum(1 for r in validation_results if r['page_exists'])\n",
    "\n",
    "print(f\"\\nüìä Validation Summary (sample of {len(sample_entries)}):\")\n",
    "print(f\"   Pages exist: {page_exists_count}/{len(sample_entries)} ({page_exists_count/len(sample_entries)*100:.1f}%)\")\n",
    "print(f\"   Content matches: {valid_count}/{len(sample_entries)} ({valid_count/len(sample_entries)*100:.1f}%)\")\n",
    "\n",
    "# Check page range validity\n",
    "min_pdf_page = min(entry.pdf_page for entry in toc_entries)\n",
    "max_pdf_page = max(entry.pdf_page for entry in toc_entries)\n",
    "pdf_page_count = len(doc)\n",
    "\n",
    "print(f\"\\nüìä Page Range Analysis:\")\n",
    "print(f\"   TOC page range: {min_pdf_page} to {max_pdf_page}\")\n",
    "print(f\"   PDF total pages: {pdf_page_count}\")\n",
    "print(f\"   Range validity: {'‚úÖ Valid' if max_pdf_page <= pdf_page_count else '‚ùå Invalid'}\")\n",
    "\n",
    "doc.close()\n",
    "print(f\"\\n‚úÖ Step 4 Complete: Validation results available for analysis\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5: Enhanced PDF Generation\n",
    "\n",
    "Create the enhanced PDF with TOC page and bookmarks for navigation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18824331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Step 5a: TOC Text Generation\n",
      "-----------------------------------\n",
      "üìÅ Loading TOC structure from: output/toc_structure.json\n",
      "   ‚úÖ Loaded 65 entries\n",
      "   üìÑ Source pages: [11, 12]\n",
      "   ‚öôÔ∏è  Page offset: 42\n",
      "üìù Generating TOC text file...\n",
      "   ‚úÖ TOC text saved to: output/generated_toc.txt\n",
      "   üìä TOC contains 65 entries\n",
      "   üìÑ Text length: 5047 characters\n",
      "\n",
      "üìù TOC Preview (first 10 lines):\n",
      "   TABLE OF CONTENTS\n",
      "   ==================================================\n",
      "   \n",
      "   Contents............................................................ 11\n",
      "   Foreword............................................................. 5\n",
      "   Preface.............................................................. 7\n",
      "   About this publication.............................................. 13\n",
      "   About the authors................................................... 19\n",
      "   Table of Cases...................................................... 21\n",
      "   MIGRATION ACT 1958................................................... 1\n",
      "   Table of Provisions.................................................. 3\n",
      "   Table of Amending Legislation....................................... 27\n",
      "   Table of Annotations................................................ 51\n",
      "   ... (55 more lines)\n",
      "\n",
      "‚úÖ Step 5a Complete: TOC text generated and ready for verification\n",
      "   üìÅ Review the TOC file: output/generated_toc.txt\n",
      "   ‚ñ∂Ô∏è  If TOC looks correct, proceed to Step 5b to create the enhanced PDF\n"
     ]
    }
   ],
   "source": [
    "# Generate TOC text for verification\n",
    "print(\"üîç Step 5a: TOC Text Generation\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Load TOC structure from JSON file created in Step 3\n",
    "import json\n",
    "\n",
    "toc_json_file = f\"{OUTPUT_DIR}/toc_structure.json\"\n",
    "print(f\"üìÅ Loading TOC structure from: {toc_json_file}\")\n",
    "\n",
    "try:\n",
    "    with open(toc_json_file, 'r', encoding='utf-8') as f:\n",
    "        toc_data = json.load(f)\n",
    "    \n",
    "    print(f\"   ‚úÖ Loaded {toc_data['metadata']['total_entries']} entries\")\n",
    "    print(f\"   üìÑ Source pages: {toc_data['metadata']['source_pages']}\")\n",
    "    print(f\"   ‚öôÔ∏è  Page offset: {toc_data['metadata']['page_offset']}\")\n",
    "    \n",
    "    # Recreate TOC entries from JSON data\n",
    "    toc_entries_from_json = []\n",
    "    for entry_dict in toc_data['entries']:\n",
    "        entry = TOCEntry(\n",
    "            title=entry_dict['title'],\n",
    "            document_page=entry_dict['document_page'],\n",
    "            pdf_page=entry_dict['pdf_page'],\n",
    "            level=entry_dict['level'],\n",
    "            page_type=entry_dict['page_type']\n",
    "        )\n",
    "        toc_entries_from_json.append(entry)\n",
    "    \n",
    "    # Use the loaded entries for TOC generation\n",
    "    toc_entries = toc_entries_from_json\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"   ‚ùå JSON file not found! Please run Step 3 first.\")\n",
    "    print(f\"   üîÑ Falling back to in-memory toc_entries if available...\")\n",
    "    if 'toc_entries' not in locals():\n",
    "        raise Exception(\"No TOC entries available. Please run Step 3 first.\")\n",
    "\n",
    "def generate_toc_text(entries: List[TOCEntry]) -> str:\n",
    "    \"\"\"Generate formatted TOC text (flat structure)\"\"\"\n",
    "    lines = [\"TABLE OF CONTENTS\", \"=\" * 50, \"\"]\n",
    "    \n",
    "    for entry in entries:\n",
    "        # No indentation - flat structure\n",
    "        title = entry.title\n",
    "        \n",
    "        # Format the line with dots\n",
    "        dots_needed = max(3, 70 - len(title) - len(str(entry.document_page)))\n",
    "        dots = \".\" * dots_needed\n",
    "        \n",
    "        formatted_line = f\"{title}{dots} {entry.document_page}\"\n",
    "        lines.append(formatted_line)\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Generate and save TOC text file\n",
    "print(\"üìù Generating TOC text file...\")\n",
    "toc_text = generate_toc_text(toc_entries)\n",
    "toc_text_file = f\"{OUTPUT_DIR}/generated_toc.txt\"\n",
    "\n",
    "with open(toc_text_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(toc_text)\n",
    "\n",
    "print(f\"   ‚úÖ TOC text saved to: {toc_text_file}\")\n",
    "print(f\"   üìä TOC contains {len(toc_entries)} entries\")\n",
    "print(f\"   üìÑ Text length: {len(toc_text)} characters\")\n",
    "\n",
    "# Preview the generated TOC\n",
    "print(f\"\\nüìù TOC Preview (first 10 lines):\")\n",
    "toc_lines = toc_text.split('\\n')\n",
    "for i, line in enumerate(toc_lines[:13]):  # Show header + 10 entries\n",
    "    print(f\"   {line}\")\n",
    "if len(toc_lines) > 13:\n",
    "    print(f\"   ... ({len(toc_lines) - 13} more lines)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Step 5a Complete: TOC text generated and ready for verification\")\n",
    "print(f\"   üìÅ Review the TOC file: {toc_text_file}\")\n",
    "print(f\"   ‚ñ∂Ô∏è  If TOC looks correct, proceed to Step 5b to create the enhanced PDF\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5b: Apply TOC to PDF\n",
    "\n",
    "Create the enhanced PDF with the verified TOC page and bookmarks for navigation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a136bd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Step 5b: Apply TOC to PDF\n",
      "------------------------------\n",
      "üìÑ Creating enhanced PDF...\n",
      "   ‚úÖ TOC page created with 65 entries\n",
      "   ‚úÖ Copied 2120 pages from original\n",
      "   üìë Adding bookmarks...\n",
      "   ‚úÖ Created 65 bookmarks\n",
      "\n",
      "üìä Enhanced PDF Results:\n",
      "   Output file: output/Migration_Legislation_with_TOC.pdf\n",
      "   Original size: 7.36 MB\n",
      "   Enhanced size: 7.37 MB\n",
      "   Size change: +0.01 MB\n",
      "   Total pages: 2121 (original: 2120)\n",
      "   TOC entries: 65\n",
      "\n",
      "‚úÖ Enhanced PDF created successfully!\n",
      "   üìÅ Enhanced PDF location: output/Migration_Legislation_with_TOC.pdf\n",
      "   üîñ 65 bookmarks added for navigation\n",
      "\n",
      "‚úÖ Step 5b Complete: Enhanced PDF generation finished\n"
     ]
    }
   ],
   "source": [
    "# Apply TOC to PDF - Create enhanced PDF with bookmarks\n",
    "print(\"üîç Step 5b: Apply TOC to PDF\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "def create_enhanced_pdf(original_path: str, toc_text: str, toc_entries: List[TOCEntry], output_path: str):\n",
    "    \"\"\"Create enhanced PDF with TOC page and bookmarks\"\"\"\n",
    "    print(\"üìÑ Creating enhanced PDF...\")\n",
    "    \n",
    "    # Open original PDF\n",
    "    original_doc = fitz.open(original_path)\n",
    "    \n",
    "    # Create new document\n",
    "    enhanced_doc = fitz.open()\n",
    "    \n",
    "    # Create TOC page using pre-generated text\n",
    "    toc_page = enhanced_doc.new_page(width=595, height=842)  # A4 size\n",
    "    \n",
    "    # Insert TOC text\n",
    "    text_rect = fitz.Rect(50, 50, 545, 792)  # Margins\n",
    "    toc_page.insert_textbox(text_rect, toc_text, fontsize=10, align=0)\n",
    "    \n",
    "    print(f\"   ‚úÖ TOC page created with {len(toc_entries)} entries\")\n",
    "    \n",
    "    # Copy all pages from original document\n",
    "    enhanced_doc.insert_pdf(original_doc)\n",
    "    \n",
    "    print(f\"   ‚úÖ Copied {len(original_doc)} pages from original\")\n",
    "    \n",
    "    # Add bookmarks using the TOC entries\n",
    "    print(f\"   üìë Adding bookmarks...\")\n",
    "    toc_outline = []\n",
    "    for entry in toc_entries:\n",
    "        # Create bookmark entry: (level, title, page_number)\n",
    "        toc_outline.append((1, entry.title, entry.pdf_page + 1))  # +1 because we added TOC page\n",
    "    \n",
    "    try:\n",
    "        enhanced_doc.set_toc(toc_outline)\n",
    "        print(f\"   ‚úÖ Created {len(toc_outline)} bookmarks\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Bookmark creation failed: {str(e)}\")\n",
    "    \n",
    "    # Save enhanced PDF\n",
    "    enhanced_doc.save(output_path)\n",
    "    enhanced_doc.close()\n",
    "    original_doc.close()\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Generate the enhanced PDF using the pre-generated TOC text\n",
    "output_pdf_path = f\"{OUTPUT_DIR}/Migration_Legislation_with_TOC.pdf\"\n",
    "enhanced_pdf = create_enhanced_pdf(PDF_PATH, toc_text, toc_entries, output_pdf_path)\n",
    "\n",
    "# Verify the output\n",
    "if os.path.exists(enhanced_pdf):\n",
    "    file_size_mb = round(os.path.getsize(enhanced_pdf) / (1024*1024), 2)\n",
    "    original_size_mb = round(os.path.getsize(PDF_PATH) / (1024*1024), 2)\n",
    "    \n",
    "    print(f\"\\nüìä Enhanced PDF Results:\")\n",
    "    print(f\"   Output file: {enhanced_pdf}\")\n",
    "    print(f\"   Original size: {original_size_mb} MB\")\n",
    "    print(f\"   Enhanced size: {file_size_mb} MB\")\n",
    "    print(f\"   Size change: {file_size_mb - original_size_mb:+.2f} MB\")\n",
    "    \n",
    "    # Quick verification\n",
    "    test_doc = fitz.open(enhanced_pdf)\n",
    "    print(f\"   Total pages: {len(test_doc)} (original: {len(fitz.open(PDF_PATH))})\")\n",
    "    print(f\"   TOC entries: {len(toc_entries)}\")\n",
    "    test_doc.close()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Enhanced PDF created successfully!\")\n",
    "    print(f\"   üìÅ Enhanced PDF location: {enhanced_pdf}\")\n",
    "    print(f\"   üîñ {len(toc_entries)} bookmarks added for navigation\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Failed to create enhanced PDF\")\n",
    "\n",
    "print(f\"\\n‚úÖ Step 5b Complete: Enhanced PDF generation finished\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
